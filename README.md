# Mechanistic Editing of Factual Knowledge in Transformers

An exploratory mechanistic interpretability project investigating how factual knowledge is stored and causally edited inside transformer models.

Using activation patching and targeted interventions on attention heads and MLP neurons, this project aims to localize and manipulate factual representations in GPT-2â€“scale models.
